# -*- coding: utf-8 -*-
"""Untitled24.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZcLKVO2y5JLWGn_okEnIzEH7IgQgbkhj
"""

import torch
import torchvision
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from torchvision import models, transforms
import matplotlib.pyplot as plt
import random
import time
import os
import glob
import torchvision.transforms.functional as TF
import numpy as np

# Device Configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"device: {device}")
# Adjust Dataset classes and channels
num_classes = 52
in_channel = 1

# Hyper-parameters for CNN
batch_size = 50
max_pool_kernel = 2
learning_rate = 0.0002
num_epochs = 15

# mount google drive
from google.colab import drive
drive.mount('/content/gdrive')

# unzip the dataset
!unzip /content/gdrive/MyDrive/2023_EEE4178_project/valid.zip

class MyDataset(Dataset):
    def __init__(self, npy_dir, label_dict=None):
        self.dir_path = npy_dir
        self.to_tensor = transforms.Compose([
            transforms.ToTensor(),
            transforms.Lambda(lambda x: x.transpose(0, 1)),
            transforms.Lambda(lambda x: TF.rotate(x, -90))
        ])
        self.npy_path = glob.glob(os.path.join(npy_dir, '*', '*.npy'))
        self.label_dict = label_dict or self.create_label_dict()

    def create_label_dict(self):
        label_dict = {}
        for path in self.npy_path:
            label_name = os.path.basename(os.path.dirname(path))
            if label_name not in label_dict:
                label_dict[label_name] = len(label_dict)
        return label_dict

    def __getitem__(self, index):
        single_data_path = self.npy_path[index]
        data = np.load(single_data_path, allow_pickle=True)

        image = data['image']
        image = self.to_tensor(image)
        image = TF.hflip(image)

        label_name = os.path.basename(os.path.dirname(single_data_path))
        label = self.label_dict[label_name]
        label = torch.tensor(label, dtype=torch.long)

        return (image, label)

    def __len__(self):
        return len(self.npy_path)

label_dict = {
    '30': 0, '31': 1, '32': 2, '33': 3, '34': 4, '35': 5, '36': 6, '37': 7, '38': 8, '39': 9,
    '41': 10, '42': 11, '43': 12, '44': 13, '45': 14, '46': 15, '47': 16, '48': 17, '49': 18,
    '4a': 19, '4b': 20, '4c': 21, '4d': 22, '4e': 23, '50': 24, '51': 25, '52': 26, '53': 27,
    '54': 28, '55': 29, '56': 30, '57': 31, '58': 32, '59': 33, '5a': 34, '61': 35, '62': 36,
    '64': 37, '65': 38, '66': 39, '67': 40, '68': 41, '69': 42, '6a': 43, '6d': 44, '6e': 45,
    '6f': 46, '71': 47, '72': 48, '74': 49, '75': 50, '79': 51,
}

# unzip 한 디렉토리 있는 path 그대로 넣어야, 디렉토리 옆 점 3개 누르면 '경로 복사' 있음 - 위의 사진 참조
test_data = MyDataset("/content/valid", label_dict)
test_loader = torch.utils.data.DataLoader(dataset=test_data,
                                           batch_size=batch_size,
                                           shuffle=True)

# device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# FIX SEED
def seed_everything(seed: int = 42):
    random.seed(seed)
    np.random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)  # type: ignore
    torch.backends.cudnn.deterministic = True  # type: ignore
    torch.backends.cudnn.benchmark = True  # type: ignore

seed_everything(42)

from torchsummary import summary
class CNN(nn.Module):
  def __init__(self, num_classes=52):
    super(CNN, self).__init__()
    self.layer1 = nn.Sequential(
        nn.Conv2d(in_channels=in_channel, out_channels=16, kernel_size=10, stride=2, padding=2), #16x48x48
        nn.BatchNorm2d(num_features=16),
        nn.SiLU(),
        nn.MaxPool2d(kernel_size=max_pool_kernel) #16x24x24
    )
    self.layer2 = nn.Sequential(
        nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2), #32x24x24
        nn.BatchNorm2d(num_features=32),
        nn.SiLU(),
        nn.MaxPool2d(kernel_size=max_pool_kernel) #32x12x12
    )
    self.layer3 = nn.Sequential(
        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=1, padding=2), #32x12x12
        nn.BatchNorm2d(num_features=32),
        nn.SiLU(),
        nn.MaxPool2d(kernel_size=max_pool_kernel) #32x6x6
    )
    self.fc1 = nn.Linear(in_features=32*6*6, out_features=512)
    self.fc2 = nn.Linear(in_features=512, out_features=128)
    self.fc3 = nn.Linear(in_features=128, out_features=num_classes)

  def forward(self, x):
    x = self.layer1(x)
    x = self.layer2(x)
    x = self.layer3(x)

    x = F.silu(x)
    x = x.reshape(x.size(0),-1)
    x = F.silu(self.fc1(x))
    x = F.sigmoid(self.fc2(x))
    x = self.fc3(x)
    return x

model = CNN().to(device)

model.load_state_dict(torch.load("/content/20171257.pth"))

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #Adam optimizer

model.eval()

with torch.no_grad():
  correct = 0

  for image, label in test_loader:
    image = image.to(device)
    label = label.to(device)

    output = model(image)
    _, pred = torch.max(output.data, 1)
    correct += (pred == label).sum().item()

  print("Accuracy of the network on the {} test images: {}%".format(len(test_data), 100 * correct / len(test_data)))